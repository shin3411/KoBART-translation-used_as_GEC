nohup: ignoring input
using cached model. /home/elice/KoBART-git/.cache/kobart_base_tokenizer_cased_cf74400bce.zip
                        input  ...                      infer
0                   높은 달 높떴다?  ...                  높은 달이 떴다.
1                어리니가 마니 사랃따.  ...               어린이가 많이 살았다.
2  나는 "이젠 살았구나"하고 굴 밖으로젠 나와따.  ...  나는 "이젠 살았구나"하고 굴 밖으로 나왔다.
3                   영호가 더워한다.  ...                  영호가 더워한다.
4          너는 앞으로 불쌍한 이를 돕겠다.  ...         나는 앞으로 불쌍한 이를 돕겠다.

[5 rows x 3 columns]
/home/elice/KoBART-translation-env/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/home/elice/KoBART-translation-env/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/home/elice/KoBART-translation-env/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 2-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
Traceback (most recent call last):
  File "infer_csv.py", line 59, in <module>
    bleu_mean = bleu_sum / num_sen
ZeroDivisionError: float division by zero
